practice|level|number|earth|name|description
SM|1|1|91|Publish process and evolve as necessary.|The process for addressing software security is published and broadcast to all stakeholders so that everyone knows the plan. Goals, roles, responsibilities, and activities are explicitly defined. Most organizations pick an existing methodology, such as the Microsoft SDL or the Synopsys Touchpoints, and then tailor it to meet their needs. Security activities, such as those grouped into an SSDL process, are adapted to software lifecycle processes (e.g., waterfall, agile, CI/CD, DevOps) so activities will evolve with both the organization and the security landscape. In many cases, the process is defined by the SSG and published only internally; it doesn't need to be publicly promoted outside the firm to have the desired impact. In addition to publishing the written process, some firms also encode it into an application lifecycle management (ALM) tool as software-defined workflow.
SM|1|3|81|Educate executives on software security.|Executives are regularly shown the ways malicious actors attack software and the negative business impacts they can have on the organization. They're also shown what other organizations are doing to mature software security, including how they deal with the risks of adopting emerging engineering methodologies with no oversight. By understanding both the problems and their proper resolutions, executives can support the SSI as a risk management necessity. In its most dangerous form, security education arrives courtesy of malicious hackers or public data exposure incidents. Preferably, the SSG will demonstrate a worst-case scenario in a controlled environment with the permission of all involved (e.g., by showing working exploits and their business impact). In some cases, presentation to the Board can help garner resources for a new or ongoing SSI efforts. Bringing in an outside guru is often helpful when seeking to bolster executive attention. Tying education to specific development areas, such as DevOps groups using cloud-native technologies, can likewise help convince leadership to accept SSG recommendations when they might otherwise be ignored in favor of faster release dates or other priorities.
SM|1|4|118|Implement lifecycle instrumentation and use to define|governance. The software security process includes conditions for release (such as gates, checkpoints, guardrails, milestones, etc.) at one or more points in a software lifecycle. The first two steps toward establishing security-specific release conditions are to identify locations that are compatible with existing development practices and to then begin gathering the input necessary to make a go/no-go decision, such as risk-ranking thresholds or defect data. Importantly, the conditions might not be verified at this stage--for example, the SSG can collect security testing results for each project prior to release, then provide their informed opinion on what constitutes sufficient testing or acceptable test results without trying to stop a project from moving forward. In CI/CD environments, shorter release cycles often require creative approaches to collecting the right evidence and rely heavily on automation. The idea of defining governance checks in the process first and enforcing them later is extremely helpful in moving development toward software security without major pain (see [SM2.2 Verify release conditions with measurements and track exceptions]). Socializing the conditions and then verifying them once most projects already know how to succeed is a gradual approach that can motivate good behavior without requiring it.
SM|2|1|63|Publish data about software security internally and drive|change. To facilitate improvement, data are published internally about the state of software security within the organization. This information might come in the form of a dashboard with metrics for executives and software development management. Sometimes, these published data won't be shared with everyone in the firm but only with relevant executives who then drive change in the organization. In other cases, open book management and data published to all stakeholders help everyone know what's going on, the philosophy being that sunlight is the best disinfectant. If the organization's culture promotes internal competition between groups, this information can add a security dimension. Increasingly, security telemetry is used to gather measurements quickly and accurately, and might initially focus less on historical trends (e.g., bugs per release) and more on speed (e.g., time to fix) and quality (e.g., defect density). Some SSIs might publish these data primarily in engineering groups within pipeline platform dashboards, democratizing measurement for developer self-improvement.
SM|2|2|60|Verify release conditions with measurements and track|exceptions. Security release conditions (or gates, checkpoints, guardrails, milestones, etc.) are verified for every project, so each project must either meet an established measure or obtain a waiver in order to move forward normally, and the SSG tracks exceptions. In some cases, measures are directly associated with regulations, contractual agreements, and other obligations, with exceptions tracked as required by statutory or regulatory drivers. In other cases, measures yield some manner of KPIs that are used to govern the process. Allowing any projects to automatically pass or granting waivers automatically without due consideration defeats the purpose of verifying conditions. Even seemingly innocuous software projects must successfully satisfy the prescribed security conditions in order to progress to or remain in production. Similarly, APIs, frameworks, libraries, bespoke code, microservices, container configurations, and so on are all software that must satisfy security release conditions. It's possible, and often very useful, to have verified the conditions both before and after the development process itself. In modern development environments, the measurement process for conditions will increasingly become automated (see [SM3.4 Integrate software-defined lifecycle governance]).
SM|2|3|60|Create or grow a satellite.|Create a collection of people scattered across the organization who show an above-average level of security interest or skill--a satellite. Forming this group of advocates, sometimes referred to as champions, is a step toward scaling security by creating a social network that speeds the adoption of security into software engineering. One way to build the initial group is to track the people who stand out during introductory training courses; see [T3.6 Identify new satellite members through observation]. Another way is to ask for volunteers. In a more top-down approach, initial satellite membership is assigned to ensure good coverage of development groups, but ongoing membership is based on actual performance. A strong satellite is a good sign of a mature SSI. The satellite can act as a sounding board for new SSG projects and, in new or fast-moving technology areas, can help combine software security skills with domain knowledge that might be under-represented in the SSG or engineering teams. Agile coaches, scrum masters, and DevOps engineers can make particularly useful satellite members, especially for detecting and removing process friction. In some agile environments, satellite-led efforts are being replaced by automation.
SM|2|6|62|Require security sign-off prior to software release.|The organization has an initiative-wide process for accepting security risk and documenting accountability, with a risk owner signing off on the state of all software prior to release. The sign-off policy might require the head of a business unit to sign-off on critical vulnerabilities that have not been mitigated or on SSDL steps that have been skipped, for example. The sign-off policy must apply both to outsourced projects and to projects that will be deployed in external environments, such as the cloud. Informal or uninformed risk acceptance alone isn't a security sign-off because the act of accepting risk is more effective when it's formalized (e.g., with a signature, a form submission, or something similar) and captured for future reference. Similarly, simply stating that certain projects don't need sign-off at all won't achieve the desired risk management results. In some cases, however, the risk owner can provide the sign-off on a particular set of software project acceptance criteria, which are then implemented in automation to provide governance-as-code, but there must be an ongoing verification that the criteria remain accurate and the automation is actually working.
SM|2|7|64|Create evangelism role and perform internal marketing.|The SSG builds support for software security throughout the organization through ongoing evangelism. This internal marketing function, often performed by a variety of stakeholder roles, keeps executives and others up to date on the magnitude of the software security problem and the elements of its solution. A scrum master familiar with security, for example, could help teams adopt better software security practices as they transform to an agile methodology. Similarly, a cloud expert could demonstrate the changes needed in security architecture and testing for software to be deployed in serverless environments. Evangelists can increase understanding and build credibility by giving talks to internal groups (including executives), publishing roadmaps, authoring technical papers for internal consumption, or creating a collection of papers, books, and other resources on an internal website and promoting its use.
SM|3|1|22|Use a software asset tracking application with portfolio|view. The SSG uses centralized tracking automation to chart the progress of every piece of software and deployable artifact (e.g., container registries) in its purview, regardless of development methodology. The automation records the security activities scheduled, in progress, and completed, incorporating results from SSDL activities even when they happen in a tight loop or during deployment. The combined inventory and security posture view enables timely decision-making. The SSG uses the automation to generate portfolio reports for multiple metrics and, in many cases, publishes these data at least among executives. Depending on the culture, this can cause interesting effects via internal competition. As an initiative matures and activities become more distributed, the SSG uses the centralized reporting system to keep track of all the moving parts.
SM|3|2|10|SSI efforts are part of external marketing.|To build external awareness, the SSG helps market the SSI beyond internal teams. In this way, software security can grow risk reduction exercises into a competitive advantage or market differentiator. The SSG might publish papers or books about its software security capabilities or have a public blog. It might provide details at external conferences or trade shows. In some cases, a complete SSDL methodology can be published and promoted outside the firm, and governance-as-code concepts can make interesting case studies. Regardless of venue, the process of sharing details externally and inviting critique is used to bring new perspectives into the firm.
SM|3|3|21|Identify metrics and use them to drive resourcing.|The SSG and its management choose the metrics that define and measure SSI progress in quantitative terms. These metrics are reviewed on a regular basis and drive the initiative's budgeting and resource allocations, so simple counts and out-of-context measurements won't suffice here. On the technical side, one such metric could be defect density, a reduction of which could be used to show a decreasing cost of remediation over time, assuming of course that testing depth has kept pace with software changes. Recall that, in agile methodologies, metrics are best collected early and often using event-driven processes with telemetry rather than point-in-time data collection. The key is to tie security results to business objectives in a clear and obvious fashion in order to justify funding. Because the concept of security is already tenuous to many business people, making an explicit tie-in can be helpful.
SM|3|4|6|Integrate software-defined lifecycle governance.|Organizations begin replacing traditional document, presentation, and spreadsheet-based lifecycle management with software-based delivery platforms. Humans, sometimes aided by tools, are no longer the primary drivers of progression from each lifecycle phase to the next. Instead, organizations rely on automation to drive the management and delivery process with ALM/ADLM software, such as Spinnaker or pipeline platform software like GitHub, and humans participate asynchronously (and often optionally), like services. Automation often extends beyond the scope of CI/CD to include functional and nonfunctional aspects of delivery, including health checks, cut-over on failure, rollback to known-good software, defect discovery and management, compliance verification, and a way to ensure adherence to policies and standards. Some organizations are also evolving their lifecycle management approach by integrating their compliance and defect discovery data to begin moving from a series of point-in-time go/no-go decisions (e.g., release conditions) to a future state of continuous accumulation of assurance data (e.g., output from sensors embedded in development and production). Lifecycle governance extends beyond defect discovery, and often includes incorporation of intelligence feeds and third-party security research, vulnerability disclosure and patching processes, as well as other activities. The Compliance & Policy practice is focused on identifying controls for compliance regimens such as PCI DSS and HIPAA, developing contractual controls such as SLAs to help control COTS software risk, setting organizational software security policy, and auditing against that policy.
CP|1|1|98|Unify regulatory pressures.|If the business or its customers are subject to regulatory or compliance drivers such as PCI security standards; GLBA, SOX, and HIPAA in the US; or GDPR in the EU, the SSG acts as a focal point for understanding the constraints such drivers impose on software. In some cases, the SSG creates or collaborates on a unified approach that removes redundancy and conflicts from overlapping compliance requirements. A formal approach will map applicable portions of regulations to controls applied to software to explain how the organization complies. As an alternative, existing business processes run by legal or other risk and compliance groups outside the SSG could also serve as the regulatory focal point. A unified set of software security guidance for meeting regulatory pressures ensures that compliance work is completed as efficiently as possible. Some firms move on to influencing the regulatory environment directly by becoming involved in standards groups exploring new technologies and mandates.
CP|1|2|114|Identify PII obligations.|The SSG plays a key role in identifying and describing PII obligations stemming from regulation and customer expectations by using this information to promote best practices related to privacy and helping translate these obligations into software requirements. The way software handles PII might be explicitly regulated, but even if it isn't, privacy is an important topic. For example, if the organization processes credit card transactions, the SSG will help in identifying the constraints that the PCI DSS places on the handling of cardholder data and then inform all stakeholders. Note that outsourcing to hosted environments (e.g., the cloud) doesn't relax PII obligations and can even increase the difficulty of recognizing and meeting all associated obligations. Also note that firms creating software products that process PII (where those firms don't necessarily handle PII directly) might meet this need by providing privacy controls and guidance for their customers. Evolving consumer privacy expectations, the proliferation of "software is in everything," and data scraping and correlation (e.g., social media) add additional expectations for PII protection.
CP|1|3|88|Create policy.|The SSG guides the rest of the organization by creating or contributing to software security policy that satisfies internal, regulatory, and customer-driven security requirements. This policy is what is permitted and denied at the initiative level; if it's not mandatory, it's not policy. It includes a unified approach for satisfying the (potentially lengthy) list of security drivers at the governance level. As a result, project teams can avoid keeping up with the details involved in complying with all applicable regulations or other mandates. Likewise, project teams won't need to relearn customer security requirements on their own. Architecture standards and coding guidelines aren't examples of policy, but policy that prescribes and mandates their use for certain software categories falls under the umbrella. In many cases, policy statements are translated into automation to provide governance-as-code, not just a process enforced by humans, but even policy that's been automated must be mandatory. In some cases, policy will be documented exclusively as governance-as-code, often as tool configuration, but must still be readily readable, auditable, and editable by humans. In some cases, satellite practitioners or similar roles are innovating and driving SSI policy locally in engineering. Because they might be new topics, codifying decisions about, for example, cloud-native technologies can rekindle interest in setting policy. Similarly, it might be necessary, for example, to explain what can and can't be automated into CI/CD pipelines (see [SM3.4 Integrate software-defined lifecycle governance]).
CP|2|1|55|Build PII inventory.|The organization identifies and tracks the kinds of PII processed or stored by each of its systems, along with their associated data repositories. A PII inventory might be approached in two ways: starting with each individual application by noting its PII use or starting with particular types of PII and noting the applications that touch them. System architectures have evolved such that PII will flow into cloud-based service and endpoint device ecosystems, and come to rest there (e.g., content delivery networks, social networks, mobile devices, IoT devices), making it tricky to keep an accurate PII inventory. In general, simply noting which applications process PII isn't enough; the type of PII and where it is stored are necessary so the inventory can be easily referenced in critical situations. This usually includes making a list of databases that would require customer notification if breached or a list to use in crisis simulations (see [CMVM3.3 Simulate software crises]).
CP|2|2|49|Require security sign-off for compliance-related risk.|The organization has a formal compliance risk acceptance and accountability process that addresses all software development projects. In that process, the SSG acts as an advisor while the risk owner signs off on the software's state prior to release based on adherence to documented criteria. For example, the sign-off policy might require the head of the business unit to sign off on compliance issues that haven't been mitigated or on compliance-related SSDL steps that have been skipped. Sign-off is explicit and captured for future reference, with any exceptions tracked, even under the fastest of application lifecycle methodologies. Note that an application without security defects might still be noncompliant, so a clean penetration test is not a substitute for a compliance sign-off. Even in DevOps organizations where engineers have the technical ability to release software, there is still a need for a deliberate risk acceptance step even if the criteria are embedded in automation. In cases where the risk owner signs off on a particular set of compliance acceptance criteria that are then implemented in automation to provide governance-as-code, there must be an ongoing verification that the criteria remain accurate and the automation is actually working.
CP|2|3|67|Implement and track controls for compliance.|The organization can demonstrate compliance with applicable requirements because its SSDL is aligned with the control statements developed by the SSG in collaboration with compliance stakeholders (see [CP1.1 Unify regulatory pressures]). The SSG collaborates with stakeholders to track controls, navigate problem areas, and ensure auditors and regulators are satisfied. The SSG might be able to remain in the background because following the SSDL automatically generates the desired compliance evidence predictably and reliably. Increasingly, the DevOps approach of embedding compliance controls in automation shows up within software-defined infrastructure and networks rather than in human process and manual intervention. A firm doing this properly can explicitly associate satisfying its compliance concerns with following its SSDL.
CP|2|4|54|Include software security SLAs in all vendor contracts.|Software vendor contracts include an SLA to ensure the vendor won't jeopardize the organization's compliance story or SSI. Each new or renewed contract contains provisions requiring the vendor to address software security and deliver a product or service compatible with the organization's security policy (see [SR2.5 Create SLA boilerplate]). In some cases, open source licensing concerns initiate the vendor management process, which can open the door for additional software security language in the SLA. Typical provisions set requirements for policy conformance, incident management, training, and defect management. Traditional IT security requirements and a simple agreement to allow penetration testing aren't sufficient here.
CP|2|5|74|Ensure executive awareness of compliance and privacy|obligations. To gain executive buy-in around compliance and privacy activities, the SSG provides executives with plain-language explanations of the organization's compliance and privacy obligations, along with the potential consequences of failing to meet those obligations. For some organizations, explaining the direct cost and likely fallout from a compliance failure or data breach can be an effective way to broach the subject. For others, having an outside expert address the Board works because some executives value an outside perspective more than an internal one. A sure sign of proper executive buy-in is an acknowledgment of the need and adequate allocation of resources to meet those obligations. While useful for bootstrapping efforts, be aware that the sense of urgency typically following a breach will not last.
CP|3|1|24|Create a regulator compliance story.|The SSG has information regulators want, so a combination of written policy, controls documentation, and artifacts gathered through the SSDL gives the SSG the ability to demonstrate the organization's compliance story without a fire drill for every audit. Often, regulators, auditors, and senior management will be satisfied with the same kinds of reports that can be generated directly from various tools. In some cases, particularly where organizations leverage shared responsibility cloud services, the organization will require additional information from vendors about how that vendor's controls support organizational compliance needs. It will often be necessary to normalize information that comes from disparate sources. While they are often the biggest, governments aren't the only regulators of behavior.
CP|3|2|18|Impose policy on vendors.|Vendors are required to adhere to the same policies used internally and must submit evidence that their software security practices pass muster. For a given organization, vendors might comprise cloud providers, middleware providers, virtualization providers, container and orchestration providers, bespoke software creators, contractors, and many more, and each might be held to different policy requirements. Evidence of their compliance could include results from SSDL activities or from tests built directly into automation or infrastructure. Vendors might attest to the fact that they perform certain SSDL processes. Policy enforcement might be through a point-in-time review (like that which assures acceptance criteria), enforced by automated checks (such as are applied to pull requests, committed artifacts like containers, or similar), or a matter of convention and protocol (e.g., services cannot connect unless particular security settings are correct, identifying certificates present, and so forth).
CP|3|3|6|Drive feedback from software lifecycle data back to policy.|Information from the software lifecycle is routinely fed back into the policy creation and maintenance process to prevent defects from occurring in the first place and to help strengthen governance-as-code practices. With this process, blind spots can be eliminated by mapping them to trends in SSDL failures. The regular appearance of inadequate architecture analysis, recurring vulnerabilities, ignored security release conditions, or the wrong firm choice for carrying out a penetration test can expose policy weakness. As an example, lifecycle data might indicate that policies impose too much bureaucracy by introducing friction that prevents engineering from meeting the expected delivery cadence. Rapid technology evolution might also create policy gaps that must be addressed. Over time, policies become more practical and easier to carry out (see [SM1.1 Publish process and evolve as necessary]). Ultimately, policies are refined with SSDL data to enhance and improve a firm's effectiveness.
T|1|1|76|Conduct software security awareness training.|To promote a culture of software security throughout the organization, the SSG conducts periodic software security awareness training. As examples, the training might be delivered via SSG members, an outside firm, the internal training organization, or e-learning. Here, the course content doesn't necessarily have to be tailored for a specific audience--for example, all developers, QA engineers, and project managers could attend the same "Introduction to Software Security" course--but this effort should be augmented with a tailored approach that addresses the firm's culture explicitly, which might include the process for building security in, avoiding common mistakes, and technology topics such as CI/CD and DevSecOps. Generic introductory courses that cover basic IT or high-level security concepts don't generate satisfactory results. Likewise, awareness training aimed only at developers and not at other roles in the organization is insufficient.
T|1|7|53|Deliver on-demand individual training.|The organization lowers the burden on students and reduces the cost of delivering training by offering on-demand training for individuals across roles. The most obvious choice, e-learning, can be kept up to date through a subscription model, but an online curriculum must be engaging and relevant to the students in various roles to achieve its intended purpose. Training that isn't used won't create any change. Hot topics like containerization and security orchestration and new delivery styles such as gamification will attract more interest than boring policy discussions. For developers, it's possible to provide training directly through the IDE right when it's needed, but in some cases, building a new skill (such as cloud security or threat modeling) might be better suited for instructor-led training, which can also be provided on demand.
T|1|8|46|Include security resources in onboarding.|The process for bringing new hires into an engineering organization requires that they complete a training module about software security. The generic new hire process usually covers topics like picking a good password and making sure that people don't follow you into the building, but this orientation period can be enhanced to cover topics such as how to create, deploy, and operate secure code, the SSDL, and internal security resources (see [SR1.2 Create a security portal]). The objective is to ensure that new hires contribute to the security culture as soon as possible. Although a generic onboarding module is useful, it doesn't take the place of a timely and more complete introductory software security course.
T|2|5|39|Enhance satellite through training and events.|The SSG strengthens the satellite network by inviting guest speakers or holding special events about advanced topics (e.g., the latest software security techniques for DevOps or cloud-native technologies). This effort is about providing to the satellite customized training so that it can fulfill its specific responsibilities, not about inviting the satellite members to routine brown bags or signing them up for the standard computer-based training. In addition, a standing conference call with voluntary attendance won't get the desired results, which are as much about building camaraderie as they are about sharing knowledge and organizational efficiency. Face-to-face meetings are by far the most effective, even if they happen only once or twice a year and some participants must attend over videoconferencing. In teams with many geographically dispersed and work-from-home members, simply turning on cameras and ensuring everyone gets a chance to speak makes a substantial difference.
T|2|8|27|Create and use material specific to company history.|To make a strong and lasting change in behavior, training includes material specific to the company's history. When participants can see themselves in a problem, they're more likely to understand how the material is relevant to their work as well as when and how to apply what they've learned. One way to do this is to use noteworthy attacks on the company's software as examples in the training curriculum. Both successful and unsuccessful attacks can make good teachable moments. Stories from company history can help steer training in the right direction, but only if those stories are still relevant and not overly censored. This training shouldn't cover platforms not used by developers (developers orchestrating containers probably won't care about old virtualization problems) or examples of problems relevant only to languages no longer in common use (e.g., Go developers probably don't need to understand how buffer overflows happen in C).
T|2|9|35|Deliver role-specific advanced curriculum.|Software security training goes beyond building awareness (see [T 1 .1 Conduct software security awareness training]) by enabling students to incorporate security practices into their work. This training is tailored to cover the tools, technology stacks, development methodologies, and bugs that are most relevant to students. An organization could offer tracks for its engineers, for example: one each for architects, developers, operations, site reliability engineers, and testers. Tool-specific training is also commonly needed in such a curriculum. While perhaps more concise than engineering training, role-specific training is necessary for many stakeholders within an organization, including product management, executives, and others. In any case, the training must be taken by a broad enough audience to build the desired skillsets.
T|3|1|6|Reward progression through curriculum.|Knowledge is its own reward, but progression through the security curriculum brings other benefits, too, such as career advancement. The reward system can be formal and lead to a certification or an official mark in the human resources system, or it can be less formal and include motivators such as documented praise at annual review time. Involving a corporate training department and/or human resources team can make security's impact on career progression more obvious, but the SSG should continue to monitor security knowledge in the firm and not cede complete control or oversight. Coffee mugs and t-shirts can build morale, but it usually takes the possibility of real career progression to change behavior.
T|3|2|23|Provide training for vendors and outsourced workers.|Vendors and outsourced workers receive the same level of software security training given to employees. Spending time and effort helping suppliers get security right at the outset is much easier than trying to determine what went wrong later on, especially if the development team has moved on to other projects. Training individual contractors is much more natural than training entire outsource firms and is a reasonable place to start. It's important that everyone who works on the firm's software has an appropriate level of training, regardless of their employment status. Of course, some vendors and outsourced workers might have received adequate training from their own firms, but that should always be verified.
T|3|3|23|Host software security events.|The organization hosts security events featuring external speakers and content in order to strengthen its security culture. Good examples of such events are Intel iSecCon and AWS re:Inforce, which invite all employees, feature external presenters, and focus on helping engineering create, deploy, and operate better code. Employees benefit from hearing outside perspectives, especially those related to fast-moving technology areas, and the organization benefits from putting its security credentials on display (see [SM3.2 SSI efforts are part of external marketing]). Events open only to small, select groups won't result in the desired culture change across the organization.
T|3|4|24|Require an annual refresher.|Everyone involved in the SSDL is required to take an annual software security refresher course. This course keeps the staff up to date on the organization's security approach and ensures the organization doesn't lose focus due to turnover, evolving methodologies, or changing deployment models. The SSG might give an update on the security landscape and explain changes to policies and standards. A refresher could also be rolled out as part of a firm-wide security day or in concert with an internal security conference, but it's useful only if it's fresh. Sufficient coverage of topics and changes from the previous year will likely comprise a significant amount of content.
T|3|5|9|Establish SSG office hours.|The SSG or equivalent stakeholder offers help to anyone during an advertised meet-up period or regularly scheduled office hours. By acting as an informal resource for people who want to solve security problems, the SSG leverages teachable moments and emphasizes the carrot over the stick approach to security best practices. Office hours might be hosted one afternoon per week by a senior SSG member, but flexible office hours are also a possibility, with visits to particular product or application groups by request, perhaps prioritizing visits by key functionality being developed and its security implications. Slack and other messaging applications can capture questions 24x7 as a good way to seed office hours conversations, but instant messages alone aren't a replacement for conversation and problem-solving.
T|3|6|4|Identify new satellite members through observation.|Recruit future satellite members (e.g., champions) by noting people who stand out during training courses, office hours, capture-the-flag exercises, hack-a-thons, and other opportunities to show skill and enthusiasm, and them encouraging them to join the satellite. Pay particular attention to practitioners contributing code, security configuration for orchestration, or defect discovery rules. The satellite often begins as an assigned collection of people scattered across the organization who show an above-average level of security interest or advanced knowledge of new technology stacks and development methodologies (see [SM2.3 Create or grow a satellite]). Identifying future members proactively is a step toward creating a social network that speeds the adoption of security into software development and operations. A group of enthusiastic and skilled volunteers will be easier to lead than a group that is drafted.
AM|1|2|77|Create a data classification scheme and inventory.|Security stakeholders in an organization agree on a data classification scheme and use it to inventory software, delivery artifacts (e.g., containers), and associated persistent stores according to the kinds of data processed or services called, regardless of deployment model (e.g., on- or off-premise). This allows applications to be prioritized by their data classification. Many classification schemes are possible--one approach is to focus on PII, for example. Depending on the scheme and the software involved, it could be easiest to first classify data repositories (see [CP2.1 Build PII inventory]) and then derive classifications for applications according to the repositories they use. Other approaches to the problem include data classification according to protection of intellectual property, impact of disclosure, exposure to attack, relevance to GDPR, and geographic boundaries.
AM|1|3|41|Identify potential attackers.|The SSG identifies potential attackers in order to understand their motivations and abilities. The outcome of this exercise could be a set of attacker profiles that includes outlines for categories of attackers and more detailed descriptions for noteworthy individuals. In some cases, a third-party vendor might be contracted to provide this information. Specific and contextual attacker information is almost always more useful than generic information copied from someone else's list. Moreover, a list that simply divides the world into insiders and outsiders won't drive useful results. Identification of attackers should account for the organization's evolving software supply chain and attack surface.
AM|1|5|61|Gather and use attack intelligence.|The SSG ensures the organization stays ahead of the curve by learning about new types of attacks and vulnerabilities. Attending technical conferences and monitoring attacker forums, then correlating that information with what's happening in the organization (perhaps by leveraging automation to mine operational logs and telemetry) helps the SSG learn more about emerging vulnerability exploitation. In many cases, a subscription to a commercial service can provide a reasonable way of gathering basic attack intelligence related to applications, APIs, containerization, orchestration, cloud environments, and so on. Regardless of its origin, attack information must be adapted to the organization's needs and made actionable and useful for developers, testers, and DevOps and reliability engineers.
AM|2|1|14|Build attack patterns and abuse cases tied to potential|attackers. The SSG prepares the organization for SSDL activities by working with stakeholders to build attack patterns and abuse cases tied to potential attackers (see [AM1.3 Identify potential attackers]). However, these resources don't have to be built from scratch for every application in order to be useful; rather, standard sets might exist for applications with similar profiles, and the SSG can add to the pile based on its own attack stories. For example, a story about an attack against a poorly designed cloud-native application could lead to a containerization attack pattern that drives a new type of testing. If a firm tracks the fraud and monetary costs associated with particular attacks, this information can in turn be used to prioritize the process of building attack patterns and abuse cases. Evolving software architectures (e.g., zero trust, serverless) might require organizations to evolve their attack pattern and abuse case creation approach and content.
AM|2|2|11|Create technology-specific attack patterns.|The SSG facilitates technology-specific attack pattern creation by collecting and providing knowledge about attacks relevant to the organization's technologies. For example, if the organization's cloud software relies on a cloud vendor's security apparatus (e.g., key and secrets management), the SSG can help catalog the quirks of the crypto package and how it might be exploited. Attack patterns directly related to the security frontier (e.g., serverless) can be useful here as well. It's often easiest to start with existing generalized attack patterns to create the needed technology-specific attack patterns, but simply adding, for example, "for microservices" at the end won't suffice.
AM|2|5|13|Maintain and use a top N possible attacks list.|The SSG periodically digests the ever-growing list of attack types and focuses the organization on prevention efforts for a prioritized short list--the top N--and uses it to drive change. This initial list almost always combines input from multiple sources, both inside and outside the organization. Some organizations prioritize their list according to perception of potential business loss while others might prioritize according to successful attacks against their software. The top N list doesn't need to be updated with great frequency, and attacks can be coarsely sorted. For example, the SSG might brainstorm twice a year to create lists of attacks the organization should be prepared to counter "now," "soon," and "someday."
AM|2|6|10|Collect and publish attack stories.|To maximize the benefit from lessons that don't always come cheap, the SSG collects and publishes stories about attacks against the organization's software. Both successful and unsuccessful attacks can be noteworthy, and discussing historical information about software attacks has the added effect of grounding software security in a firm's reality. This is particularly useful in training classes to help counter a generic approach that might be overly focused on other organizations' top 10 lists or outdated platform attacks (see [T2.8 Create and use material specific to company history]). Hiding or overly sanitizing information about attacks from people building new systems fails to garner any positive benefits from a negative happenstance.
AM|2|7|16|Build an internal forum to discuss attacks.|The organization has an internal, interactive forum where the SSG, the satellite, incident response, and others discuss attacks and attack methods. The discussion serves to communicate the attacker perspective to everyone. The SSG can also maintain an internal mailing list that encourages subscribers to discuss the latest information on publicly known incidents. Dissection of attacks and exploits that are relevant to a firm are particularly helpful when they spur discussion of development, infrastructure, and other mitigations. Simply republishing items from public mailing lists doesn't achieve the same benefits as active discussion, nor does a closed discussion hidden from those actually creating code. Everyone should feel free to ask questions and learn about vulnerabilities and exploits (see [SR1.2 Create a security portal]).
AM|3|1|5|Have a research group that develops new attack methods.|A research group works to identify and defang new classes of attacks before attackers even know that they exist. Because the security implications of new technologies might not have been fully explored in the wild, doing it in-house is sometimes the best way forward. This isn't a penetration testing team finding new instances of known types of weaknesses--it's a research group that innovates new types of attacks. Some firms provide researchers time to follow through on their discoveries using bug bounty programs or other means of coordinated disclosure. Others allow researchers to publish their findings at conferences like DEF CON to benefit everyone.
AM|3|2|4|Create and use automation to mimic attackers.|The SSG arms engineers, testers, and incident response with automation to mimic what attackers are going to do. For example, a new attack method identified by an internal research group or a disclosing third party could require a new tool, so the SSG could package the tool and distribute it to testers. The idea here is to push attack capability past what typical commercial tools and offerings encompass, and then make that knowledge and technology easy for others to use. Tailoring these new tools to a firm's particular technology stacks and potential attackers increases the overall benefit. When technology stacks and coding languages evolve faster than vendors can innovate, creating tools and automation in-house might be the best way forward. In the DevOps world, these tools might be created by engineering and embedded directly into toolchains and automation (see [ST3.6 Implement event-driven security testing in automation]).
AM|3|3|6|Monitor automated asset creation.|The SSG guides the implementation of technology controls that provide a continuously updated view of the various network, machine, software, and related infrastructure assets being instantiated by engineering teams as part of their ALM processes. To help ensure proper coverage, the SSG works with engineering teams to understand orchestration, cloud configuration, and other self-service means of software delivery used to quickly stand-up servers, databases, networks, and entire clouds for software deployments. Monitoring the changes in application design (e.g., moving a monolithic application to microservices) is also part of this effort. This monitoring requires a specialized effort--normal system, network, and application logging and analysis won't suffice. Success might require a multi-pronged approach, including consuming orchestration and virtualization metadata, querying cloud service provider APIs, and outside-in web crawling and scraping. As processes improve, the data will be helpful for threat modeling efforts (see [AA1.1 Perform security feature review]).
SFD|1|1|102|Integrate and deliver security features.|Rather than having each project team implement its own security features (e.g., authentication, role management, key management, logging, cryptography, protocols), the SSG provides proactive guidance by acting as or facilitating a clearinghouse of security features for engineering groups to use. These features might be discovered during SSDL activities, created by the SSG or specialized development teams, or defined in configuration templates (e.g., cloud blueprints) and delivered via mechanisms such as containers, microservices, and APIs. Generic security features often have to be tailored for specific platforms. For example, each mobile and cloud platform will likely need their own means by which users are authenticated and authorized, secrets are managed, and user actions are centrally logged and monitored. Project teams benefit from implementations that come preapproved by the SSG, and the SSG benefits by not having to repeatedly track down the kinds of subtle errors that often creep into security features. It's the implementation of these defined security features that generate real progress, not simply making the list.
SFD|1|2|83|Engage the SSG with architecture teams.|Security is a regular topic in the organization's software architecture discussions, with the architecture team taking responsibility for security in the same way that it takes responsibility for performance, availability, scalability, and resiliency. One way to keep security from falling out of these discussions is to have an SSG member participate in architecture discussions. Increasingly, architecture discussions include developers and site reliability engineers governing all types of software components, such as open source, APIs, containers, and cloud services. In other cases, enterprise architecture teams can help the SSG create secure designs that integrate properly into corporate design standards. Proactive engagement by the SSG is key to success here. Moving a well-known system to the cloud means reengaging the SSG, for example. It's never safe for one team to assume another team has addressed security requirements.
SFD|2|1|33|Leverage secure-by-design components and services.|The SSG takes a proactive role in software design by building or providing pointers to secure-by-design software components and services. In addition to teaching by example, these resilient building blocks aid important efforts such as architecture analysis and code review by making it easier to spot errors and avoid mistakes. These components and services, whether created internally or available from service providers, often have features (e.g., application identity, RBAC) that enable uniform security orchestration across, for example, multi-environment deployments. Similarly, the SSG might further leverage this information by tailoring code review rules specifically for the components it offers (see [CR2.6 Use automated tools with tailored rules]). When integrating software components, including open source and cloud services, the SSG must carefully vet the software for security before publication.
SFD|2|2|55|Create capability to solve difficult design problems.|The SSG contributes to building resilient architectures by solving design problems unaddressed by organizational security components or services, or by cloud service providers, thus minimizing the negative impact that security has on other constraints (e.g., feature velocity). Involving the SSG in the design of a new protocol, microservice, or architecture decision (e.g., containerization) enables timely analysis of the security implications of existing defenses and identifies elements that should be refactored, duplicated, or avoided. Likewise, having a security architect understand the security implications of moving a seemingly well-understood application to the cloud saves a lot of headaches later. Designing for security up front is more efficient than analyzing an existing design for security and refactoring when flaws are uncovered, so the SSG should be involved early in the new project process. The SSG could also get involved in what could have historically been purely engineering discussions, as even rudimentary (e.g., "Hello, world!") use of cloud-native technologies requires configurations and other capabilities that have direct implications on security posture. Note that some design problems will require specific expertise outside of the SSG: even the best expert can't scale to cover the needs of an entire software portfolio.
SFD|3|1|16|Form a review board or central committee to approve and|maintain secure design patterns. A review board or central committee formalizes the process of reaching consensus on design needs and security tradeoffs. Unlike a typical architecture committee focused on functions, this group focuses on providing security guidance and also periodically reviews already published design standards (especially around authentication, authorization, and cryptography) to ensure that design decisions don't become stale or out of date. A review board can help control the chaos associated with adoption of new technologies when development groups might otherwise make decisions on their own without engaging the SSG. Review board security guidance also serves to inform outsourced software providers about security expectations (see [CP3.2 Impose policy on vendors]).
SFD|3|2|15|Require use of approved security features and frameworks.|Implementers take their security features and frameworks from an approved list or repository. There are two benefits to this activity: developers don't spend time reinventing existing capabilities, and review teams don't have to contend with finding the same old defects in new projects or when new platforms are adopted. Essentially, the more a project uses proven components, the easier testing, code review, and architecture analysis become (see [AA1.1 Perform security feature review]). Reuse is a major advantage of consistent software architecture and is particularly helpful for agile development and velocity maintenance in CI/CD pipelines. Packaging and applying required components facilitates delivering services as software features (e.g., identity-aware proxies). Containerization makes it especially easy to package and reuse approved features and frameworks (see [SE2.5 Use application containers]).
SFD|3|3|5|Find and publish secure design patterns from the|organization. The SSG fosters centralized design reuse by collecting secure design patterns (sometimes referred to as security blueprints) from across the organization and publishing them for everyone to use. A section of the SSG website could promote positive elements identified during threat modeling or architecture analysis so that good ideas are spread. This process is formalized: an ad hoc, accidental noticing isn't sufficient. In some cases, a central architecture or technology team can facilitate and enhance this activity. Common design patterns accelerate development, so it's important to use secure design patterns not just for applications but for all software assets (microservices, APIs, containers, infrastructure, and automation).
SR|1|1|90|Create security standards.|The SSG meets the organization's demand for security guidance by creating standards that explain the required way to adhere to policy and carry out specific security-centric operations. A standard might describe how to perform identity-based application authentication or how to determine the authenticity of a software update, perhaps with the SSG ensuring the availability of a reference implementation. Standards often apply to software beyond the scope of an application's code, including container construction, orchestration (e.g., infrastructure-as-code), and service mesh configuration. Standards can be deployed in a variety of ways to keep them actionable and relevant. They can be automated into development environments (e.g., worked into an IDE or toolchain), or they can be explicitly linked to code examples and deployment artifacts (e.g., containers). In any case, to be considered standards, they must be adopted and enforced.
SR|1|2|88|Create a security portal.|The organization has a well-known central location for information about software security. Typically, this is an internal website maintained by the SSG that people refer to for the latest and greatest on security standards and requirements, as well as for other resources provided by the SSG (e.g., training). An interactive wiki is better than a static portal with guideline documents that rarely change. Organizations can supplement these materials with mailing lists, chat channels, and face-to-face meetings. Development teams are increasingly putting software security knowledge directly into toolchains and automation that is outside the organization (e.g., GitHub), but that does not remove the need for SSG-led knowledge management.
SR|1|3|99|Translate compliance constraints to requirements.|Compliance constraints are translated into software requirements for individual projects and communicated to the engineering teams. This is a linchpin in the organization's compliance strategy: by representing compliance constraints explicitly with requirements and informing stakeholders, the organization demonstrates that compliance is a manageable task. For example, if the organization routinely builds software that processes credit card transactions, PCI DSS compliance plays a role in the SSDL during the requirements phase. In other cases, technology standards built for international interoperability can include security guidance on compliance needs. Representing these standards as requirements also helps with traceability and visibility in the event of an audit. It's particularly useful to codify the requirements into reusable code or artifact deployment specifications.
SR|2|2|64|Create a standards review board.|The organization creates a review board to formalize the process used to develop standards and to ensure that all stakeholders have a chance to weigh in. This standards review board could operate by appointing a champion for any proposed standard, putting the onus on the champion to demonstrate that the standard meets its goals and to get approval and buy-in from the review board. Enterprise architecture or enterprise risk groups sometimes take on the responsibility of creating and managing standards review boards. When the standards are implemented directly as software, the responsible champion might be a DevOps manager, release engineer, or whoever owns the associated deployment artifact (e.g., orchestration code).
SR|2|4|74|Identify open source.|Open source components included in the software portfolio and integrated at runtime are identified and reviewed to understand their dependencies. Organizations use a variety of tools and metadata provided by delivery pipelines to discover old versions of components with known vulnerabilities or that their software relies on multiple versions of the same component. Automated tools for finding open source, whether whole components or large chunks of borrowed code, are one way to approach this activity. Some software development pipeline platforms, container registries, and middleware platforms such as RedHat's OpenShift, have begun to provide this visibility as metadata resulting from behind-the-scenes artifact scanning. An informal annual review or a process that relies solely on developers asking for permission does not generate satisfactory results. Some organizations combine composition analysis results from multiple phases of the software lifecycle in order to get a more complete and accurate view of the open source being included.
SR|2|5|55|Create SLA boilerplate.|The SSG works with the legal department to create standard SLA boilerplate for use in contracts with vendors and outsource providers (including cloud providers) to require software security efforts. The legal department understands that the boilerplate also helps prevent compliance and privacy problems. Under the agreement, vendors and outsource providers must meet company-mandated software security standards (see [CP2.4 Include software security SLAs in all vendor contracts]). Boilerplate language might call for objective third-party insight into software security efforts, such as BSIMMsc measurements or BSIMM scores.
SR|3|1|35|Control open source risk.|The organization has control over its exposure to the risks that come along with using open source components and all the involved dependencies, including dependencies integrated at runtime. The use of open source could be restricted to predefined projects or to a short list of open source versions that have been through an approved security screening process, have had unacceptable vulnerabilities remediated, and are made available only through specific internal repositories and containers. For some use cases, policy might preclude any use of open source. The legal department often spearheads additional open source controls due to the "viral" license problem associated with GPL code. SSGs that partner with and educate the legal department on open source security risks can help move an organization to improve its open source risk management practices, which must be applied across the software portfolio to be effective.
SR|3|2|13|Communicate standards to vendors.|The SSG works with vendors to educate them and promote the organization's security standards. A healthy relationship with a vendor isn't guaranteed through contract language alone, so the SSG should engage with vendors, discuss vendor security practices, and explain in concrete terms (rather than legalese) what the organization expects of its vendors. Any time a vendor adopts the organization's security standards, it's a clear sign of progress. Note that standards implemented as security features or infrastructure configuration could be a requirement to services integration with a vendor (see [SFD1.1 Integrate and deliver security features]). When the firm's SSDL is publicly available, communication regarding software security expectations is easier. Likewise, sharing internal practices and measures can make expectations clear.
SR|3|3|9|Use secure coding standards.|Secure coding standards help the organization's developers avoid the most obvious bugs and provide ground rules for code review. These standards are necessarily specific to a programming language or platform, and they can address the use of popular frameworks, APIs, libraries, and infrastructure automation. Platforms might include mobile or IoT runtimes, cloud service provider APIs, orchestration runtimes, and SaaS platforms (e.g., Salesforce, SAP). If the organization already has coding standards for other purposes, its secure coding standards should build upon them. A clear set of secure coding standards is a good way to guide both manual and automated code review, as well as to provide relevant examples for security training. Some groups might choose to integrate their secure coding standards directly into automation. While enforcement isn't the point at this stage (see [CR3.5 Enforce secure coding standards]), violation of the standards is a good teachable moment for all stakeholders. Socializing the benefits of following the standards is also a good first step to gaining widespread acceptance.
SR|3|4|20|Create standards for technology stacks.|The organization standardizes on specific technology stacks. This means a reduced workload because teams don't have to explore new technology risks for every new project. The organization might create a secure base configuration (commonly in the form of golden images, AMIs, etc.) for each technology stack, further reducing the amount of work required to use the stack safely. In cloud environments, hardened configurations likely include up-to-date security patches, security configuration, and security services, such as logging and monitoring. In traditional on-premise IT deployments, a stack might include an operating system, a database, an application server, and a runtime environment (e.g., a LAMP stack). Where the technology will be reused, such as containers, microservices, or orchestration code, the security frontier is a good place to find traction; standards for secure use of these reusable technologies means that getting security right in one place positively impacts the security posture of all downstream dependencies (see [SE2.5 Use application containers]).
AA|1|1|113|Perform security feature review.|Security-aware reviewers identify the security features in an application and its deployment configuration (authentication, access control, use of cryptography, etc.), then inspect the design and runtime parameters for problems that would cause these features to fail at their purpose or otherwise prove insufficient. For example, this kind of review would identify both a system that was subject to escalation of privilege attacks because of broken access control as well as a mobile application that incorrectly puts PII in local storage. In some cases, use of the firm's secure-by-design components can streamline this process (see [SFD2.1 Leverage secure-by-design components and services]). Organizations often carry out security feature review with checklist-driven analysis and procedural threat modeling efforts. Many modern applications are no longer simply "3-tier" but instead involve components architected to interact across a variety of tiers: browser/endpoint, embedded, web, microservices, orchestration engines, deployment pipelines, third-party SaaS, and so on. Some of these environments might provide robust security feature sets, whereas others might have key capability gaps that require careful consideration, so organizations should not consider the applicability and correct use of security features in just one tier of the application but across all tiers that constitute the architecture and operational environment.
AA|1|2|49|Perform design review for high-risk applications.|The organization can learn the benefits of design review by seeing real results for a few high-risk, high-profile applications. Reviewers must have some experience performing detailed design reviews and breaking the design under consideration, especially for new platforms or environments. Even if the SSG isn't yet equipped to perform an in-depth architecture analysis (see [AA2.1 Define and use AA process]), smart people with an adversarial mindset can find important design problems. In all cases, a design review should produce a set of flaws and a plan to mitigate them. An organization can use consultants to do this work, but it should participate actively. Ad hoc review paradigms that rely heavily on expertise can be used here, but they don't tend to scale in the long run. A review focused only on whether a software project has performed the right process steps won't generate useful results about flaws. Note that a sufficiently robust design review process can't be executed at CI/CD speed.
AA|1|3|37|Have SSG lead design review efforts.|The SSG takes a lead role in AA by performing a design review to uncover flaws. Breaking down an architecture is enough of an art that the SSG must be proficient at it before it can turn the job over to architects, and proficiency requires practice. The SSG can't be successful on its own, either; it will likely need help from architects or implementers to understand the design. With a clear design in hand, the SSG might be able to carry out the detailed review with a minimum of interaction with the project team. Over time, the responsibility for leading review efforts should shift toward software security architects. Approaches to AA evolve over time, so it's wise to not expect to set a process and use it forever.
AA|1|4|62|Use a risk methodology to rank applications.|To facilitate security feature and design review processes, the SSG or other assigned groups use a defined risk methodology, which might be implemented via questionnaire or similar method--whether manual or automated--to collect information about each application in order to assign a risk classification and associated prioritization. Information needed for an assignment might include, "Which programming languages is the application written in?" or "Who uses the application?" or "Is the application's deployment software-orchestrated?" Typically, a qualified member of the application team provides the information, where the process should be short enough to take only a few minutes. Some teams might use automation to gather the necessary data. The SSG can use the answers to categorize the application as, for example, high, medium, or low risk. Because a risk questionnaire can be easy to game, it's important to put into place some spot-checking for validity and accuracy. An overreliance on self-reporting or automation can render this activity useless.
AA|2|1|29|Define and use AA process.|The SSG defines and documents a process for AA and applies it in the design reviews it conducts to find flaws. This process includes a standardized approach for thinking about attacks, vulnerabilities, and various security properties. In addition to the technical impact discussions, the process includes a focus on the associated risk, such as through frequency or probability analysis, that gives stakeholders the information necessary to make decisions. The process is defined well enough that people outside the SSG can carry it out. It's important to document both the architecture under review and any security flaws uncovered, as well as risk information people can understand and use. Microsoft's STRIDE and Synopsys's ARA are examples of such a process, although even these two methodologies for AA have evolved greatly over time. Individual ad hoc approaches to AA don't count as a defined process.
AA|2|2|28|Standardize architectural descriptions.|Defined AA processes use an agreed-upon format to describe architecture, including a means for representing data flow. Combining a documented process along with standardized architecture descriptions will make AA tractable for people who aren't security experts. High-level network diagrams, data flow, and authorization flows are always useful, but the description should go into detail about how the software itself is structured. A standard architecture description can be enhanced to provide an explicit picture of information assets that require protection, including useful metadata. Standardized icons that are consistently used in diagrams, templates, and whiteboard squiggles are especially useful, too.
AA|3|1|16|Have engineering teams lead AA process.|Engineering teams lead the AA process most of the time. This effort requires a well-understood and well-documented process (see [AA2.1 Define and use AA process]), although the SSG still might contribute to AA in an advisory capacity or under special circumstances. Even with a good process, consistency is difficult to attain because breaking architecture requires experience, so provide architects with SSG or outside expertise on novel issues. In any given organization, the identified engineering team might normally have responsibilities such as development, DevOps, cloud security, operations security, security architecture, or a variety of similar roles.
AA|3|2|2|Drive analysis results into standard architecture patterns.|Failures identified during AA are fed back to engineering teams so that similar mistakes can be prevented in the future through improved design patterns (see [SFD3.1 Form a review board or central committee to approve and maintain secure design patterns]). Cloud service providers have learned a lot about how their platforms and services fail to resist attack and have codified this experience into patterns for secure use. Organizations who heavily rely on these services might base their application-layer patterns on those building blocks provided by the cloud service provider (for example, AWS CloudFormation and Azure Blueprints) in making their own. Note that security design patterns can interact in surprising ways that break security, so the AA process should be applied even when vetted design patterns are in standard use.
AA|3|3|11|Make the SSG available as an AA resource or mentor.|To build an AA capability outside of the SSG, the SSG advertises itself as a resource or mentor for teams that ask for help in using the AA process (see [AA2.1 Define and use AA process]) to conduct their own design reviews. The SSG might answer AA questions during office hours and, in some cases, might assign someone to sit with the architect for the duration of the analysis. In the case of high-risk software, the SSG should play a more active mentorship role in applying the AA process.
CR|1|2|80|Perform opportunistic code review.|The SSG ensures code review for high-risk applications is performed in an opportunistic fashion, such as by following up a design review with a code review looking for security issues in not only source code and dependencies but also deployment artifact configuration (e.g., containers) and automation metadata (e.g., infrastructure-as-code). This informal targeting often evolves into a systematic approach. Code review could involve the use of specific tools and services, or it might be manual, but it has to be part of a proactive process. When new technologies pop up, new approaches to code review might become necessary.
CR|1|4|102|Use automated tools.|Static analysis incorporated into the code review process makes the review more efficient and consistent. Automation won't replace human judgement, but it does bring definition to the review process and security expertise to reviewers who typically aren't security experts. Note that a specific tool might not cover an entire portfolio, especially when new languages are involved, so additional local effort might be useful. Some organizations might progress to automating tool use by instrumenting static analysis into source code management workflows (e.g., pull requests) and delivery pipeline workflows (build, package, and deploy) to make the review more efficient, consistent, and in line with release cadence. Whether use of automated tools is to review a portion of the source code incrementally, such as a developer committing new code or small changes, or to conduct full-program analysis by scanning the entire codebase, this service should be explicitly connected to a larger SSDL defect management process applied during software development, not just used to "check the security box" on the path to deployment.
CR|1|5|49|Make code review mandatory for all projects.|Code review is mandatory for all projects under the SSG's purview, with a lack of code review or unacceptable results stopping a release, slowing it down, or causing it to be recalled. While all projects must undergo code review, the process might be different for different kinds of projects. The review for low-risk projects might rely more heavily on automation, for example, whereas high-risk projects might have no upper bound on the amount of time spent by reviewers. Having a minimum acceptable standard forces projects that don't pass to be fixed and reevaluated. A code review tool with nearly all the rules turned off (so it can run at CI/CD automation speeds, for example) won't provide sufficient defect coverage. Similarly, peer code review or tools focused on quality and style won't provide useful security results.
CR|1|6|32|Use centralized reporting to close the knowledge loop.|The bugs found during code review are tracked in a centralized repository that makes it possible to do both summary and trend reporting for the organization. The code review information can be incorporated into a CISO-level dashboard that might include feeds from other parts of the security organization (e.g., penetration tests, security testing, black-box testing, and white-box testing). Given the historical code review data, the SSG can also use the reports to demonstrate progress and drive the training curriculum (see [SM2.5 Identify metrics and use them to drive budgets]). Individual bugs make excellent training examples. Some organizations have moved toward analyzing this data and using the results to drive automation.
CR|1|7|51|Assign tool mentors.|Mentors are available to show developers how to get the most out of code review tools. If the SSG has the most skill with the tools, it could use office hours or other outreach to help developers establish the right configuration or get started on interpreting results. Alternatively, someone from the SSG might work with a development team for the duration of the first review they perform. Centralized use of a tool can be distributed into the development organization or toolchains over time through the use of tool mentors, but providing installation instructions and URLs to centralized tools isn't the same as mentoring. Increasingly, mentorship extends to tools associated with deployment artifacts (e.g., container security) and infrastructure (e.g., cloud configuration). In many organizations, satellite members (e.g., champions) take on the tool mentorship role.
CR|2|6|25|Use automated tools with tailored rules.|Custom rules are created and used to help uncover security defects specific to the organization's coding standards or the framework-based or cloud-provided middleware it uses. The same group that provides tool mentoring (see [CR1.7 Assign tool mentors]) will likely spearhead this customization. Tailored rules can be explicitly tied to proper usage of technology stacks in a positive sense and avoidance of errors commonly encountered in a firm's codebase in a negative sense. To reduce the workload for everyone, many organizations also create rules to remove repeated false positives and turn off checks that aren't relevant.
CR|2|7|17|Use a top N bugs list (real data preferred).|The SSG maintains a living list of the most important kinds of bugs that it wants to eliminate from the organization's code and uses it to drive change. Many organizations start with a generic list pulled from public sources, but lists such as the OWASP Top 10 rarely reflect an organization's bug priorities. The list's value comes from being specific to the organization, built from real data gathered from code review, testing, software composition analysis, and actual incidents, and prioritized for prevention efforts. Simply sorting the day's bug data by number of occurrences won't produce a satisfactory list because these data change so often. To increase interest, the SSG can periodically publish a "most wanted" report after updating the list. One potential pitfall with a top N list is that it tends to only include known problems. Of course, just building the list won't accomplish anything; everyone has to use it to fix bugs.
CR|3|2|9|Build a capability to combine assessment results.|Combine assessment results so that multiple analysis techniques feed into one reporting and remediation process. In addition to code review, analysis techniques might include dynamic analysis, software composition analysis, container scanning, cloud services monitoring, and so on. The SSG might write scripts to gather data automatically and combine the results into a format that can be consumed by a single downstream review and reporting solution. The tricky part of this activity is normalizing vulnerability information from disparate sources that use conflicting terminology. In some cases, using a standardized taxonomy (e.g., a CWE-like approach) can help with normalization. Combining multiple sources helps drive better-informed risk mitigation decisions.
CR|3|3|4|Create capability to eradicate bugs.|When a new kind of bug is discovered in the firm's software, the SSG ensures rules are created to find it and helps use these rules to identify all occurrences of the new bug throughout the codebases and runtime environments. It becomes possible to eradicate the bug type entirely without waiting for every project to reach the code review portion of its lifecycle. A firm with only a handful of software applications built on a single technology stack will have an easier time with this activity than firms with many large applications built on a diverse set of technology stacks. A new development framework or library, rules in RASP or a next-generation firewall, or using cloud configuration tools to provide guardrails can often help in eradication efforts.
CR|3|4|1|Automate malicious code detection.|Automated code review is used to identify dangerous code written by malicious in-house developers or outsource providers. Examples of malicious code that could be targeted include backdoors, logic bombs, time bombs, nefarious communication channels, obfuscated program logic, and dynamic code injection. Although out-of-the-box automation might identify some generic malicious-looking constructs, custom rules for the static analysis tools used to codify acceptable and unacceptable code patterns in the organization's codebase will quickly become a necessity. Manual code review for malicious code is a good start but insufficient to complete this activity at scale. While not all backdoors or similar code were meant to be malicious when they were written (e.g., a developer's feature to bypass authentication during testing), such things have a tendency to stay in deployed code and should be treated as malicious code until proven otherwise.
CR|3|5|0|Enforce coding standards.|The enforced portions of an organization's secure coding standards often start out as a simple list of banned functions, with a violation of these standards being sufficient grounds for rejecting a piece of code. Other useful coding standard topics might include proper use of cloud APIs, use of approved cryptography, memory sanitization, and many others. Code review against standards must be objective: it shouldn't become a debate about whether the noncompliant code is exploitable. In some cases, coding standards are specific to language constructs and enforced with tools (e.g., codified into SAST rules). In other cases, published coding standards are specific to technology stacks and enforced during the code review process or using automation. Standards can be positive ("do it this way") or negative ("do not use this API"), but they must be enforced to be useful.
ST|1|1|100|Ensure QA performs edge/boundary value condition testing.|QA efforts go beyond functional testing to perform basic adversarial tests and probe simple edge cases and boundary conditions, with no particular attacker skills required. When QA understands the value of pushing past standard functional testing that uses expected input, it begins to move slowly toward thinking like an adversary. A discussion of boundary value testing can lead naturally to the notion of an attacker probing the edges on purpose (for example, determining what happens when someone enters the wrong password over and over).
ST|1|3|87|Drive tests with security requirements and security|features. QA targets declarative security mechanisms with tests derived from requirements and security features. A test could try to access administrative functionality as an unprivileged user, for example, or verify that a user account becomes locked after some number of failed authentication attempts. For the most part, security features can be tested in a fashion similar to other software features--security mechanisms such as account lockout, transaction limitations, entitlements, and so on are tested with both expected and unexpected input as derived from requirements. Software security isn't security software, but testing security features is an easy way to get started. New software architectures and deployment automation, such as with container and cloud infrastructure orchestration, might require novel test approaches.
ST|1|4|50|Integrate opaque-box security tools into the QA process.|The organization uses one or more opaque-box security testing tools as part of the QA process. Such tools are valuable because they encapsulate an attacker's perspective, albeit generically. Traditional dynamic analysis scanners are relevant for web applications, while similar tools exist for cloud environments, containers, mobile applications, embedded systems, and so on. In some situations, other groups might collaborate with the SSG to apply the tools. For example, a testing team could run the tool but come to the SSG for help with interpreting the results. When testing is integrated into agile development approaches, opaque-box tools might be hooked into internal toolchains, provided by cloud-based toolchains, or used directly by engineering. Regardless of who runs the opaque-box tool, the testing should be properly integrated into a QA cycle of the SSDL and will often include both authenticated and unauthenticated reviews..
ST|2|4|19|Share security results with QA.|The SSG or others with security testing data routinely share results from security reviews with those responsible for QA. Using security testing results as the basis for a conversation about common attack patterns or the underlying causes of security defects allows QA to generalize that information into new test approaches. Organizations that have chosen to leverage software pipeline platforms such as GitHub, or CI/CD platforms such as the Atlassian stack, can benefit from QA receiving various testing results automatically, which should then facilitate timely stakeholder conversations. In some cases, these platforms can be used to integrate QA into automated remediation workflow and reporting by generating change request tickets for developers, lightening the QA workload. Over time, QA learns the security mindset, and the organization benefits from an improved ability to create security tests tailored to the organization's code.
ST|2|5|21|Include security tests in QA automation.|Security tests are included in an automation framework and run alongside other QA tests. While many groups trigger these tests manually, in a modern toolchain, these tests are likely part of the pipeline and triggered through automation. Security tests might be derived from abuse cases identified earlier in the lifecycle (see [AM2.1 Build attack patterns and abuse cases tied to potential attackers]), from creative tweaks of functional tests, developer tests, and security feature tests, or even from guidance provided by penetration testers on how to reproduce an issue.
ST|2|6|15|Perform fuzz testing customized to application APIs.|QA efforts include running a customized fuzzing framework against APIs critical to the organization. They could begin from scratch or use an existing fuzzing toolkit, but the necessary customization often goes beyond creating custom protocol descriptions or file format templates to giving the fuzzing framework a built-in understanding of the application interfaces it calls into. Test harnesses developed explicitly for particular applications make good places to integrate fuzz testing.
ST|3|3|8|Drive tests with risk analysis results.|Testers use architecture analysis results (see [AA 2.1 Define and use AA process]) to direct their work. If the AA determines that "the security of the system hinges on the transactions being atomic and not being interrupted partway through," for example, then torn transactions will become a primary target in adversarial testing. Adversarial tests like these can be developed according to risk profile, with high-risk flaws at the top of the list. Security testing results shared with QA (see [ST 2.4 Share security results with QA]) can help focus test creation on areas of potential vulnerability that can, in turn, help prove the existence of identified high-risk flaws.
ST|3|4|2|Leverage coverage analysis.|Testers measure the code coverage of their security tests (see [ST2.5 Include security tests in QA automation]) to identify code that isn't being exercised and then adjust automation (see [ST3.6 Implement event-driven security testing in automation]) to incrementally improve coverage. In turn, code coverage analysis drives increased security testing depth. Standard-issue black-box testing tools achieve exceptionally low coverage, leaving a majority of the software under test unexplored, which isn't a testing best practice. Coverage analysis is easier when using standard measurements such as function coverage, line coverage, or multiple condition coverage.
ST|3|5|2|Begin to build and apply adversarial security tests (abuse|cases). QA begins to incorporate test cases based on abuse cases (see [AM2.1 Build attack patterns and abuse cases tied to potential attackers]) as testers move beyond verifying functionality and take on the attacker's perspective. One way to do this is to systematically attempt to replicate incidents from the organization's history. Abuse and misuse cases based on the attacker's perspective can also be derived from security policies, attack intelligence, standards, and the organization's top N attacks list (see [AM2.5 Build and maintain a top N possible attacks list]). This effort turns the corner from testing features to attempting to break the software under test.
ST|3|6|2|Implement event-driven security testing in automation.|The SSG guides implementation of automation for continuous, event-driven application security testing. Event-driven testing implemented in ALM automation typically moves the testing closer to the conditions driving the testing requirement (whether shift left toward design or shift right toward operations), repeats the testing as often as the event is triggered as software moves through ALM, and helps ensure the right testing is executed for a given set of conditions. This might be instead of or in addition to software arriving at a gate or checkpoint and triggering a point-in-time security test. Success with this approach depends on broad use of sensors (e.g., agents, bots) that monitor engineering processes, execute contextual rules, and provide telemetry to automation that initiates the specified testing whenever event conditions are met. More mature configurations proceed to including risk-driven conditions.
PT|1|1|111|Use external penetration testers to find problems.|External penetration testers are used to demonstrate that the organization's code needs help. Breaking a high-profile application to provide unmistakable evidence that the organization isn't somehow immune to the problem often gets the right attention. Over time, the focus of penetration testing moves from trying to determine if the code is broken in some areas to a sanity check done before shipping. External penetration testers that bring a new set of experiences and skills to the problem are the most useful.
PT|1|2|98|Feed results to the defect management and mitigation|system. Penetration testing results are fed back to development through established defect management or mitigation channels, with development responding via a defect management and release process. Emailing the results to various people doesn't generate useful results. Properly done, this exercise demonstrates the organization's ability to improve the state of security, and many firms are emphasizing the critical importance of not just identifying but actually fixing security problems. One way to ensure attention is to add a security flag to the bug-tracking and defect management system. The organization might leverage developer workflow or social tooling (e.g., Slack, JIRA) to communicate change requests, but those requests are still tracked explicitly as part of a vulnerability management process.
PT|1|3|88|Use penetration testing tools internally.|The organization creates an internal penetration testing capability that uses tools. This capability (e.g., group, team) can be part of the SSG or part of a specialized team elsewhere in the organization, with the tools complementing manual efforts to improve the efficiency and repeatability of the testing process. Tools used usually include off-the-shelf products built specifically for application penetration testing, network penetration tools that specifically understand the application layer, container and cloud configuration testing tools, and custom scripts. Free-time or crisis-driven efforts aren't the same as an internal capability.
PT|2|2|33|Penetration testers use all available information.|Penetration testers, whether internal or external, use source code, design documents, architecture analysis results, misuse and abuse cases, code review results, and cloud environment and other deployment configuration to do deeper analysis and find more interesting problems. To effectively do their job, penetration testers often need everything created throughout the SSDL, so an SSDL that creates no useful artifacts about the code will make this effort harder. Having access to the artifacts is not the same as using them.
PT|2|3|34|Schedule periodic penetration tests for application|coverage. The SSG collaborates in periodically testing all applications in its purview according to an established schedule, which could be tied to a calendar or a release cycle. High-profile applications should get a penetration test at least once a year, even if new releases haven't yet moved into production. This testing serves as a sanity check and helps ensure that yesterday's software isn't vulnerable to today's attacks. The testing can also help maintain the security of software configurations and environments, especially containers and components in the cloud. One important aspect of periodic testing is to make sure that the problems identified are actually fixed and don't creep back into the build. New automation created for CI/CD deserves penetration testing as well.
PT|3|1|23|Use external penetration testers to perform deep-dive|analysis. The organization uses external penetration testers to do deep-dive analysis for critical projects and to introduce fresh thinking into the SSG. These testers should be domain experts and specialists who keep the organization up to speed with the latest version of the attacker's perspective and have a track record for breaking the type of software being tested. Skilled penetration testers will always break a system, but the question is whether they demonstrate new kinds of thinking about attacks that can be useful when designing, implementing, and hardening new systems. Creating new types of attacks from threat intelligence and abuse cases typically requires extended timelines, which is essential when it comes to new technologies, and prevents checklist-driven approaches that look only for known types of problems.
PT|3|2|12|Customize penetration testing tools.|The SSG collaborates in either creating penetration testing tools or adapting publicly available ones to more efficiently and comprehensively attack the organization's software. Tools will improve the efficiency of the penetration testing process without sacrificing the depth of problems that the SSG can identify. Automation can be particularly valuable in organizations using agile methodologies because it helps teams go faster. Tools that can be tailored are always preferable to generic tools. Success here is often dependent upon both the depth of tests and their scope.
SE|1|1|80|Use application input monitoring.|The organization monitors the input to the software that it runs in order to spot attacks. For web code, a WAF can do this job, while other kinds of software likely require other approaches, including runtime instrumentation. The SSG might be responsible for the care and feeding of the monitoring system, but incident response isn't part of this activity. For web applications, WAFs that write log files can be useful if someone periodically reviews the logs and takes action. Other software and technology stacks, such as mobile and IoT, likely require their own input monitoring solutions. Serverless and containerized software can require interaction with vendor software to get the appropriate logs and monitoring data. Cloud deployments and platform-as-a-service usage can add another level of difficulty to the monitoring, collection, and aggregation approach.
SE|1|2|117|Ensure host and network security basics are in place.|The organization provides a solid foundation for its software by ensuring that host (whether bare metal or virtual machine) and network security basics are in place across its data centers and networks and that these basics remain in place during new releases. Evolving network perimeters, increased connectivity and data sharing, and increasing dependence on vendors (e.g., content delivery, load balancing, and content inspection services) add a degree of difficulty to getting and keeping the basics right. Doing software security before getting host and network security in place is like putting on shoes before putting on socks.
SE|2|2|48|Define secure deployment parameters and configurations.|The SSDL requires creating an installation guide or a clearly described configuration for deployable software artifacts and the infrastructure-as-code necessary to deploy them, helping teams install and configure software securely. When special steps are required to ensure a deployment is secure, these steps can be outlined in a configuration guide or explicitly described in deployment automation, including information on COTS, vendor, and cloud services components. In some cases, installation guides are not used internally but are distributed to customers who buy the software. All deployment automation should be understandable by humans, not just by machines. Increasingly, secure deployment parameters and configuration are codified into infrastructure scripting (e.g., Terraform, Helm, Ansible, and Chef).
SE|2|4|32|Protect code integrity.|The organization can attest to the provenance, integrity, and authorization of important code before allowing it to execute. While legacy and mobile platforms accomplished this with point-in-time code signing and permissions activity, protecting modern containerized software demands actions in various lifecycle phases. Organizations can use build systems to verify sources and manifests of dependencies, creating their own cryptographic attestation of both. Packaging and deployment systems can sign and verify binary packages, including code, configuration, metadata, code identity, and authorization material. In some cases, organizations allow only code from their own registries to execute in certain environments. With many DevOps practices greatly increasing the number of people who can touch the code, organizations should also use permissions and peer review to govern code commits within source code management to help protect integrity.
SE|2|5|44|Use application containers to support security goals.|The organization uses application containers to support its software security goals, which likely include ease of deployment, a tighter coupling of applications with their dependencies, immutability, integrity (see [SE2.4 Protect code integrity]), and some isolation benefits without the overhead of deploying a full operating system on a virtual machine. Containers provide a convenient place for security controls to be applied and updated consistently. While containers can be useful in development and test environments, production use provides the needed security benefits.
SE|2|6|59|Ensure cloud security basics.|Organizations should already be ensuring that their host and network security basics are in place, but they must also ensure that basic requirements are met in cloud environments. Of course, cloud-based virtual assets often have public-facing services that create an attack surface (e.g., cloud-based storage) that is different from the one in a private data center, so these assets require customized security configuration and administration. In the increasingly software-defined world, the SSG has to help everyone explicitly implement cloud-based security features and controls (some of which can be built in, for example, cloud provider administration consoles) that are comparable to those built with cables and physical hardware in private data centers. Detailed knowledge about cloud provider shared responsibility security models is always necessary.
SE|2|7|33|Use orchestration for containers and virtualized|environments. The organization uses automation to scale service, container, and virtualized environments in a disciplined way. Orchestration processes take advantage of built-in and add-on security features (see [SFD2.1 Leverage secure-by- design components and services]), such as hardening against drift, secrets management, and rollbacks, to ensure that each deployed workload meets predetermined security requirements. Setting security behaviors in aggregate allows for rapid change when the need arises. Orchestration platforms are themselves software that become part of your production environment, which in turn requires hardening and security patching and configuration; in other words, if you use Kubernetes, make sure you patch Kubernetes.
SE|3|2|13|Use code protection.|To protect intellectual property and make exploit development harder, the organization erects barriers to reverse engineering its software (e.g., anti-tamper, debug protection, anti-piracy features, runtime integrity). This is particularly important for widely distributed code such as mobile applications and JavaScript distributed to browsers. For some software, obfuscation techniques could be applied as part of the production build and release process. In other cases, these protections could be applied at the software-defined network or software orchestration layer when applications are being dynamically regenerated post-deployment. On some platforms, employing Data Execution Prevention (DEP), Safe Structured Handling (SafeSEH), and Address Space Layout Randomization (ASLR) can be a good start at making exploit development more difficult.
SE|3|3|9|Use application behavior monitoring and diagnostics.|The organization monitors production software to look for misbehavior or signs of attack. This activity goes beyond host and network monitoring to look for software-specific problems, such as indications of malicious behavior, fraud, and related issues. Intrusion detection and anomaly detection systems at the application level might focus on an application's interaction with the operating system (through system calls) or with the kinds of data that an application consumes, originates, and manipulates. In any case, the signs that an application isn't behaving as expected will be specific to the software and its environment, so one-size-fits-all solutions probably won't generate satisfactory results. In some types of environments (e.g., PaaS), some of this data and the associated predictive analytics might come from a vendor.
SE|3|6|14|Enhance application inventory with operations bill of|materials. A list of applications and their locations in production environments is essential information for any well-run enterprise (see [CMVM2.3 Develop an operations inventory of software delivery value streams]). In addition, a manifest detailing the components, dependencies, configurations, external services, and so on for all production software helps the organization to tighten its security posture--that is, to react with agility as attackers and attacks evolve, compliance requirements change, and the number of items to patch grows quite large. Knowing where all the components live in running software--whether they're in private data centers, in clouds, or sold as box products--allows for timely response when unfortunate events occur. Done properly, institutional use of container security solutions can make inventory efforts much simpler.
CMVM|1|1|108|Create or interface with incident response.|The SSG is prepared to respond to an event or alert and is regularly included in the incident response process, either by creating its own incident response capability or by regularly interfacing with the organization's existing team. A standing meeting between the SSG and the incident response team can keep information flowing in both directions. Having pre-built communication channels with critical vendors (e.g., infrastructure, SaaS, PaaS) is also very important.
CMVM|1|2|96|Identify software defects found in operations monitoring|and feed them back to development. Defects identified in production through operations monitoring are fed back to development and used to change developer behavior. The contents of production logs can be revealing (or can reveal the need for improved logging). Entering incident triage data into an existing bug-tracking system (perhaps by making use of a special security flag) can close the information loop and make sure that security issues get fixed. Increasingly, organizations are relying on telemetry provided by agents packaged with software as part of cloud security posture monitoring, container configuration monitoring, RASP, or similar products to detect software defects or adversaries' exploration prior to exploit. In most cases, organizations must also rely on additional analysis tools (e.g., ELK, Datadog) to aggregate and correlate that avalanche of data and provide useful input to development. In the best of cases, processes in the SSDL can be improved based on operational data (see [CMVM3.2 Enhance the SSDL to prevent software bugs found in operations]).
CMVM|2|1|92|Have emergency response.|The organization can make quick code and configuration changes when software (e.g., application, API, microservice, infrastructure) is under attack, with a rapid-response team working in conjunction with application owners, developers, operators, and the SSG to study the code and the attack, find a resolution, and fix the production code (e.g., push a patch into production, rollback to a known-good version, deploy a new container). Often, the emergency response team is the engineering team itself. A well-defined process is a must here, but a process that has never been used might not actually work.
CMVM|2|2|93|Track software bugs found in operations through the fix|process. Defects found in operations are entered into established defect management systems and tracked through the fix process. This capability could come in the form of a two-way bridge between bug finders and bug fixers, but make sure the loop is closed completely. Bugs can crop up in all types of deployable artifacts, deployment automation, and infrastructure configuration. Setting a security flag in the bug-tracking system can help facilitate tracking.
CMVM|2|3|61|Develop an operations inventory of software delivery|value streams. The organization has a map of its software deployments, related containerization and orchestration automation code, and deployment automation code, along with the respective owners that contribute to business value streams. If a software asset needs to be changed, operations or DevOps teams can reliably identify both the stakeholders and all the places where the change needs to be deployed. Common components shared between multiple projects can be noted so that, when an error occurs in one application, other applications that share the same components can be fixed as well. Accurately representing an inventory will likely involve enumerating at least the source code, the open source incorporated both during the build and during dynamic production updates, the orchestration software incorporated into production images, and any service discovery or invocation that occurs in production.
CMVM|3|1|4|Fix all occurrences of software bugs found in operations.|The organization fixes all instances of each bug found during operations--not just the small number of instances that trigger bug reports--to meet recovery, continuity, and resiliency goals. Doing this proactively requires the ability to reexamine the entire inventory of software delivery value streams when new kinds of bugs come to light (see [CR3.3 Create capability to eradicate bugs]). One way to approach this is to create a ruleset that generalizes a deployed bug into something that can be scanned for via automated code review. Use of orchestration can greatly simplify deploying the fix for all occurrences of a software bug (see [SE3.5 Use orchestration for containers and virtualized environments]).
CMVM|3|2|11|Enhance the SSDL to prevent software bugs found in|operations. Experience from operations leads to changes in the SSDL, which can in turn be strengthened to prevent the reintroduction of bugs found during operations. To make this process systematic, incident response postmortem could include a feedback-to-SSDL step. The outcomes of the postmortem might result in changes such as tool-based policy rulesets in a CI/CD pipeline and adjustments to automated deployment configuration (see [SM3.4 Integrated software-defined lifecycle governance]). This works best when root-cause analysis pinpoints where in the software lifecycle an error could have been introduced or slipped by uncaught. DevOps engineers might have an easier time with this because all the players are likely involved in the discussion and the solution. An ad hoc approach to SSDL improvement isn't sufficient.
CMVM|3|3|14|Simulate software crises.|The SSG simulates high-impact software security crises to ensure software incident detection and response capabilities minimize damage. Simulations could test for the ability to identify and mitigate specific threats or, in other cases, begin with the assumption that a critical system or service is already compromised and evaluate the organization's ability to respond. Planned chaos engineering can be effective at triggering unexpected conditions during simulations. The exercises must include attacks or other software security crises at the appropriate software layer to generate useful results (e.g., at the application layer for web applications and at lower layers for IoT devices). When simulations model successful attacks, an important question to consider is the time required to clean up. Regardless, simulations must focus on security-relevant software failure and not on natural disasters or other types of emergency response drills. Organizations that are highly dependent on vendor infrastructure (e.g., cloud service providers, SaaS, PaaS) and security features will naturally include those things in crisis simulations.
CMVM|3|4|20|Operate a bug bounty program.|The organization solicits vulnerability reports from external researchers and pays a bounty for each verified and accepted vulnerability received. Payouts typically follow a sliding scale linked to multiple factors, such as vulnerability type (e.g., remote code execution is worth $10,000 versus CSRF is worth $750), exploitability (demonstrable exploits command much higher payouts), or specific service and software versions (widely deployed or critical services warrant higher payouts). Ad hoc or short-duration activities, such as capture-the-flag contests or informal crowd-sourced efforts, don't constitute a bug bounty program.
CMVM|3|5|10|Automate verification of operational infrastructure|security. The SSG works with engineering teams to facilitate a controlled self-service process that replaces some traditional IT efforts, such as application and infrastructure deployment, and includes verification of security properties (e.g., adherence to agreed-upon security hardening). Engineers now create networks, containers, and machine instances, orchestrate deployments, and perform other tasks that were once IT's sole responsibility (see [AM3.3 Monitor automated asset creation]). In facilitating this change, the organization uses machine-readable policies and configuration standards to automatically detect issues such as configuration drift and report on infrastructure that does not meet expectations (see [SE2.2 Define secure deployment parameters and configurations]). In some cases, the automation makes changes to running environments to bring them into compliance. In many cases, organizations use a single policy to manage automation in different environments, such as in multi-cloud and hybrid-cloud environments.
CMVM|3|6|0|Publish risk data for deployable artifacts.|The organization collects and publishes risk telemetry about the applications, services, APIs, containers, and other software it deploys. Published information extends beyond basic software security (see [SM2.1 Publish data about software security internally]) and inventory data (see [SM3.1 Use a software asset tracking application with portfolio view]) to include information about constituency of the software (e.g., bill of materials), what group created it and how, and the risks associated with vulnerability, security controls, or other characteristics intrinsic to each artifact. This approach stimulates cross-functional coordination and helps stakeholders take informed risk management action. In some cases, much of this information is created by automated processes and associated with a registry that provides stakeholder visibility. Making a list of risks that aren't used for decision support won't achieve useful results.
CMVM|3|7|0|Streamline incoming responsible vulnerability disclosure.|The SSG provides external bug reporters with a line of communication to internal security experts through a low- friction, public entry point. These experts work with bug reporters to invoke any necessary organizational responses and coordinate with the external entities throughout the defect management lifecycle. Successful disclosure processes require insight from internal stakeholders such as legal, marketing, and public relations roles to simplify and expedite the decision-making during software security crises. Although bug bounties may be important to motivate some researchers (see [CMVM3.4] Operate a bug bounty program), proper public attribution and a low- friction reporting process is often sufficient motivation for researchers to participate in a coordinated disclosure. Most organizations will use a combination of easy-to-find landing pages, common email addresses (security@), and embedded product documentation when appropriate (security.txt) as an entry point for external reporters to invoke this process.
